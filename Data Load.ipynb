{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as tr \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 파이토치 제공 데이터 사용\n",
    "\n",
    "논문에서 테스트용으로 많이 사용 (검증된 데이터이다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. 데이터 전처리 설정 \n",
    "transf = tr.Compose([tr.Resize(8), tr.ToTensor()])\n",
    "\n",
    "#compose 내에서 순서대로 전처리 \n",
    "# 8x8로 크기 변환, 텐서 데이터로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499072it [02:01, 1402834.48it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#b. 데이터 다운받기 \n",
    "\n",
    "# transform  데이터 전처리를 의미함 pad, grayscale 등등 \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download=True, transform=transf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainset[0][0].size()\n",
    "#튜플형태 이미지/데이터 \n",
    "# 3channel, 8*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. 데이터 셋을 받아 우리가 원하는 배치 형태로 만들기 \n",
    "#num_workers는 서브 프로세서를 몇개를 쓰는가 에러나면 0으로 설정하면 됨.\n",
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)\n",
    "\n",
    "# 5만개 데이터, 배치 사이즈 = 50, 따라서 mini batch의 개수는 1000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 8, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한 묶음에 대해 불러오기 \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images.size()\n",
    "# 배치 사이즈, 채널수, 8*8(image size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 같은 클래스 별 폴더 이미지 데이터 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#./class/tiger \n",
    "# ./class/lion\n",
    "\n",
    "#전처리 작업 정의 \n",
    "transf = tr.Compose([tr.Resize(16), tr.ToTensor()])\n",
    "#레이블이 자동으로 매겨짐 + 데이터 전처리\n",
    "trainset = torchvision.datasets.ImageFolder(root='./class', transform = transf)\n",
    "#실제 활용을 위해 batchsize 만들음\n",
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=False, num_workers=2)\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 개인 데이터 사용 + 전처리 \n",
    "### type A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 32, 32, 3) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "#이미지 개수, 채널 수, 이미지 너비, 높이 \n",
    "# 20개 32*32, 3channel \n",
    "train_images = np.random.randint(256, size=(20,32,32,3))\n",
    "train_labels = np.random.randint(2, size=(20,1))\n",
    "\n",
    "#전처리 코드 추가 진행해야함 \n",
    "\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set을 상속받을 class 생성 \n",
    "\n",
    "class TensorData(Dataset):\n",
    "    #외부에서 데이터가 들어오는 구조 \n",
    "        #폴더정리를 못하는 경우 \n",
    "            # 1. 다른 작업과 공용으로 사용하는 경우 (거기서도 작업이 이루어져야하기 때문에 디렉을 바꿀 수 없음 )\n",
    "            # 2. 폴더가 아닌 SQL같은 곳에서 넘어오는 경우 \n",
    "        #파이토치 같은 경우 제공하는 전처리는 부족함 \n",
    "    def __init__(self, x_data, y_data):\n",
    "        #텐서 변환 \n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        #이미지 개수, 채널 수, 이미지 너비, 높이로 순서변환 \n",
    "        self.x_data = self.x_data.permute(0,3,1,2) \n",
    "        self.y_data = torch.LongTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "    \n",
    "    #데이터 외부로 내보냄 \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorData(train_images, train_labels)\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터가 이미지개수, 채널수, 크기로 알맞게 변했는지 확인 \n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 개인 데이터 사용 + 전처리 \n",
    "### type B\n",
    "우리가 가지고 있는 데이터를 파이토치 TRANSFORM 이용하여 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set을 상속받을 class 생성 \n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform \n",
    "        self.len = len(y_data)\n",
    "        \n",
    "    \n",
    "    #데이터 외부로 내보냄 \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.transform(index), self.y_data[index]\n",
    "        \n",
    "        #데이터 전처리를 하고 내보냄 \n",
    "        #정의해놓은 트랜스폼이 없다면 (none)전처리를 하지 않고 내보냄 \n",
    "        if self.transform :\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len \n",
    "    \n",
    "# 위 클래스는 type a와는 다르게 tensor 변환부가 없음 따라서 다른 클래스에서 정의함 \n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample \n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        inputs = inputs.permute(2,0,1)\n",
    "        return inputs, torch.LongTensor(labels)\n",
    "    \n",
    "class LinearTensor:\n",
    "    def __init__(self, slope=1, bias=0):\n",
    "        self.slope = slope\n",
    "        self.bias = bias \n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        inputs = self.slope*inputs + self.bias \n",
    "        return inputs, labels \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = tr.Compose([ToTensor(), LinearTensor(2,5)])\n",
    "ds1 = MyDataset(train_images, train_labels, transform=trans)\n",
    "#batch 형태로 만들기 위해 dataloader 이용 \n",
    "train_loader1 = DataLoader(ds1, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만들어서 써야하는 이용 \n",
    "데이터 타입(numpy)이 tr에 맞지 않기 때문에 스스로 정의하여 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set을 상속받을 class 생성 \n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform \n",
    "        self.len = len(y_data)\n",
    "        \n",
    "    \n",
    "    #데이터 외부로 내보냄 \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.transform(index), self.y_data[index]\n",
    "        \n",
    "        #데이터 전처리를 하고 내보냄 \n",
    "        #정의해놓은 트랜스폼이 없다면 (none)전처리를 하지 않고 내보냄 \n",
    "        if self.transform :\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len \n",
    "    \n",
    "class MyTransform :\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample \n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        inputs = inputs.permute(2,0,1)\n",
    "        labels = torch.FloatTensor(labels)\n",
    "        \n",
    "        transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor(), tr.Normalize(0.5, 0.5, 0.5),(0.5,0.5,\n",
    "        final_output=transf(inputs)\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = ds2[0]\n",
    "features, labels = first_data\n",
    "print(type(fatures), type(labels))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
